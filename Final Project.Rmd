---
title: "Regork Telecom Analysis"
author: "Berkley Dixon"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```


# {.tabset}
## Introduction

Regork just decided to add telecom services to its business, and they want to accurately predict whether a customer is still with the company or has left. With this ability, they can adjust their offerings to keep current customers for longer, which will lead to more monthly revenue. In our exploratory data analysis, we discovered two notable relationships: one relating Tenure and Status, in which a majority of Left customers had a very low tenure, and one between customer Tenure and Payment Method, in which customers with higher tenure overwhelmingly used automatic payment methods instead of check-based methods. We utilized three different models to predict customer status: MARS, bagging, and random forest. After our model training, our MARS model was the best, with a mean AUC of 0.85. Our MARS model showed that customer Tenure, Total Charges, and Payment Method were the most influential in predicting customer status. We recommend that the Regork Telecom CEO offer incentives for current customers that do not use an automatic payment method to switch to an automatic method, as customers with high tenure overwhelmingly use automatic payment methods. 

## Data Preparation and Exploratory Data Analysis

The following packages are used in the analysis:

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(tidymodels)
library(baguette)
library(ggplot2)
library(ranger)
library(vip)
```

Before we begin exploring our dataset, we need to first import our data! We will also clean up our data and remove any missing values.

```{r}
telecom <- read.csv("data/customer_retention.csv")
telecom <- telecom %>% mutate(Status = as.factor(Status)) %>%
  filter(TotalCharges != "NA")
```

Now let's find some trends within our dataset!

```{r}
telecom %>%
  ggplot(aes(x = Tenure)) +
  geom_histogram(bins = 50, fill = "lightcyan3") +
  facet_wrap(~ Status) +
  labs(title = "Tenure and Customer Status",
       x = "Tenure (months)",
       y = "Number of Customers")
```

This plot gives us some interesting information. It seems that a lot of customers leave within the first few months--perhaps a "free trial"-type promotion is offered and causes customers to begin using the service, but they cancel it within that first month because they just wanted the free month or didn't like the service. In addition, not many people leave after passing a year or two of tenure. We'll likely see in our models that higher tenure values lead to a prediction of a customer's status being Current.


```{r}
telecom %>%
  ggplot(aes(x = Tenure, fill = PaymentMethod)) +
  geom_histogram(bins = 10) +
  labs(title = "Tenure based on Payment Method",
       x = "Tenure (Months)",
       y = "Number of Customers",
       fill = "Payment Method")
```

This plot gives us a great idea of the relationship between payment method and customer tenure. Automatic payment methods are correlated to higher customer tenure, either because it's less effort to complete an automatic payment or because customers forget about their subscription. Similarly, customers may forget to pay with non-automatic payment methods or might find it too cumbersome to pay through that method or change their method, so they instead stop using the service.


## Machine Learning

Before creating our different models, we first need to split our data into training and testing sets. We'll use a 70/30 split for this.

```{r}
# split data into training and testing sets
set.seed(123)
telecom_split <- initial_split(telecom, prop = 0.7, strata = "Status") 
tele_train <- training(telecom_split)
tele_test <- testing(telecom_split)
```

Now we will create a few different models to predict whether a customer's Status is Current or Left. First, we'll do a MARS model.

```{r}
tele_recipe <- recipe(Status ~ ., data = tele_train) %>%
  step_YeoJohnson(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())

set.seed(123)
kfolds <- vfold_cv(tele_train, v = 5, strata = Status)

mars_mod <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_mode("classification")

tele_mars_grid <- grid_regular(num_terms(range = c(1,30)), prod_degree(), levels = 25)

telecom_wf <- workflow() %>%
  add_recipe(tele_recipe) %>%
  add_model(mars_mod)

mars_results <- telecom_wf %>%
  tune_grid(resamples = kfolds, grid = tele_mars_grid)

mars_results %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  arrange(desc(mean)) %>%
  head()
```

The optimal MARS model has an average AUC of 0.850 with 14 nodes and a prod_degree of 1.

Next, let's do a more interesting type of model that incorporates some randomness--a bagged decision model.

```{r}
# creating model recipe
model_recipe <- recipe(Status ~ ., data = tele_train)

# creating 5-fold cross validation
set.seed(123)
kfolds <- vfold_cv(tele_train, v = 5)

# creating bagging model
bagging_model <- bag_tree() %>%
  set_engine("rpart", times = tune()) %>%
  set_mode("classification")

# create the hyperparameter grid
bagging_hyper_grid <- expand.grid(times = c(5, 25, 50, 100, 200, 300))

# train our model across the hyper parameter grid 
set.seed(123)
bagging_results <- tune_grid(bagging_model, model_recipe, resamples = kfolds, grid = bagging_hyper_grid)

# model results 
show_best(bagging_results, metric = "roc_auc")
```

According to the tibble above, 200 bagged trees does the best, with a mean AUC of 0.82. This is worse than our MARS model.


Finally, we'll do a random forest model. 

```{r}
randfor_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()) %>%
  set_engine("ranger", importance = "impurity")

# hyperparameter grid to create different forests
rf_hyper_grid <- grid_regular( 
  trees(range = c(5, 250)),
  mtry(range = c(2, 19)),
  min_n(range = c(1, 20)),
  levels = 5
)
```

``` {r}
# training model
set.seed(123)
randfor_results <- tune_grid(randfor_model, model_recipe, resamples = kfolds, grid = rf_hyper_grid)

# 5 best forests ranked by area under the curve (accuracy)
show_best(randfor_results, metric = "roc_auc")
```

Our best random forest model is slightly better than our bagging model, with a mean AUC value of 0.843. The optimal forest has 250 trees, a minimum of 20 observations under each split, and 2 features being considered at each split.

Because our MARS model had the highest mean AUC, we'll look further into that model to see what's affecting it most and how accurate it actually is.

```{r}
best_hyperparameters <- select_best(mars_results, metric = "roc_auc")

final_wf <- workflow() %>%
  add_recipe(tele_recipe) %>%
  add_model(mars_mod) %>%
  finalize_workflow(best_hyperparameters)

# Step 2. fit our final workflow object across the full training set data
final_fit <- final_wf %>%
  fit(data = tele_train)

# Step 3. plot the top 10 most influential features 
final_fit %>%
  extract_fit_parsnip() %>%
  vip() +
  labs(title = "Most Important Features in MARS Model",
       y = "Feature",
       x = "Importance")
```

According to our importance plot, Tenure (months), Total Charges, and Payment Method are the most influential factors in our model. 

```{r}
autoplot(mars_results) +
  labs(title = "Accuracy and Area Under Curve of MARS model",
       x = "Number of Terms in the Model")
```

This plot shows that as the number of terms in our MARS model increases, so do the accuracy and AUC. Our model reaches about 81% accuracy and 0.85 AUC by ~20 terms. We can also see why our model chose to use a prod_degree of 1 rather than 2, as the higher degree leads to more inaccuracy.

```{r}
final_fit %>% 
  predict(tele_test, type = "prob") %>%
  mutate(truth = tele_test$Status) %>%
  roc_auc(truth, .pred_Current)
```

```{r}
final_fit %>%
   predict(tele_test) %>%
   bind_cols(tele_test %>% select(Status)) %>%
   conf_mat(truth = Status, estimate = .pred_class)
```

This confusion matrix shows us that our model is about 90% accurate in predicting current customers' status, but is only about 56% accurate with customers with the Left status, which means there are a lot of false positives but not many false negatives.


Finally, we will use our MARS model to predict monthly losses with no changes.

```{r}
loss <- final_fit %>%
  predict(tele_test) %>%
  bind_cols(tele_test %>% select(MonthlyCharges)) %>%
  filter(.pred_class == "Left") %>%
  summarize(Loss = sum(MonthlyCharges))

total_monthly_rev <- final_fit %>%
  predict(tele_test) %>%
  bind_cols(tele_test %>% select(MonthlyCharges)) %>%
  summarize(TotalMonthlyRev = sum(MonthlyCharges))

loss/total_monthly_rev
```

Our predicted monthly loss if every customer that the MARS model predicted will leave actually does leave (not considering the inaccuracies of our model) is $36,857.85. This is approximately 27% of our total monthly revenue of our test customers.



## Summary

Based on our model results, the Regork CEO should utilize the MARS model we created in order to predict whether a customer is going to leave in the future. Factors such as tenure, total charges, and payment method are the most influential in determining a customer's Status, and our model is accurate, on average, 81% of the time. Unfortunately, the model is not particularly good at accurately predicting a Left status, which may cause problems when determining strategy to keep customers. This inaccuracy is likely because of the low proportion of Left status customers in the data set. In the future, as more customers start using the service and the proportion of Current to Left customers increases, though, the model will likely become worse and worse at accurately predicting the status of Left customers.

If Regork does nothing, our model predicts that 27% of current monthly revenue ($36,857) will be lost to customers leaving. The best course of action by Regork to keep current customers, based on our data, is to offer an incentive for customers that do not currently use an automatic payment method to switch to an automatic method. This will decrease customers leaving due to the cumbersome nature of their payment method and will likely cause many customers to forget they have a Regork subscription, which will lead to longer tenure. Decreasing monthly charges will also likely lead to longer customer tenure. Combining this with making the unsubscribing process difficult and/or expensive will also increase customer tenure as many customers that want to unsubscribe will find it too much effort to unsubscribe.

The main limitation of our analysis is the low overall proportion of Left customers versus Current customers. Therefore, any model that is trained on our dataset will struggle to accurately predict Left status, which is an unfortunate downside to our dataset. However, increasing the proportion of Left status customers is not ideal, of course, so we do the best we can!